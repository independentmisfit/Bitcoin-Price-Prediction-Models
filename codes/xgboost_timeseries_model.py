# -*- coding: utf-8 -*-
"""XGBOOST TIMESERIES MODEL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iFP9HNPgDWleQjPyATx4XIWCwDOho0ru
"""

import matplotlib.pyplot as plt
from xgboost import XGBRegressor
import pandas as pd
import numpy as np

bitcoin_data = pd.read_csv('bitcoin data.csv')

bitcoin_data.isnull().sum()

bitcoin_data.duplicated().sum()

bitcoin_df = pd.DataFrame({
    'Start': pd.to_datetime(bitcoin_data['Start']),
    'Open': bitcoin_data['Open']
})
bitcoin_df.rename(columns={'Start': 'Date'}, inplace=True)
bitcoin_df.head()

new_bitcoin_df = bitcoin_df.iloc[29:]
new_bitcoin_df.sort_values(by='Date', inplace=True)
new_bitcoin_df.reset_index(drop=True, inplace=True)
new_bitcoin_df.head()

n_lags = 60
for lag in range(1, n_lags + 1):
    new_bitcoin_df[f'Open_Lag_{lag}'] = new_bitcoin_df['Open'].shift(lag)
new_bitcoin_df = new_bitcoin_df.dropna()
new_bitcoin_df.head()

new_bitcoin_df.info()

new_bitcoin_df['15_day_MA'] = new_bitcoin_df['Open'].rolling(window=15).mean()
new_bitcoin_df['30_day_MA'] = new_bitcoin_df['Open'].rolling(window=30).mean()
new_bitcoin_df['60_day_MA'] = new_bitcoin_df['Open'].rolling(window=60).mean()
new_bitcoin_df['90_day_MA'] = new_bitcoin_df['Open'].rolling(window=90).mean()
new_bitcoin_df.dropna(inplace=True)
new_bitcoin_df.head()

X = new_bitcoin_df.drop(['Date', 'Open'], axis = 1)
y = new_bitcoin_df['Open']

train_size = int(len(new_bitcoin_df) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from sklearn.model_selection import TimeSeriesSplit, GridSearchCV
# from sklearn.metrics import mean_squared_error
# tscv = TimeSeriesSplit(n_splits=5)
# xgb_model = XGBRegressor()
# param_grid = {
#     'n_estimators': [50, 75, 100, 125],
#     'learning_rate': [0.01, 0.1, 0.2, 0.3],
#     'max_depth': [3, 4, 5, 6],
#     'subsample': [0.8, 0.9, 1.0],
#     'colsample_bytree': [0.8, 0.9, 1.0],
# }
# scoring = ['neg_mean_squared_error', ]
# xgb_cv = GridSearchCV(xgb_model, param_grid, cv=tscv, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)
# xgb_cv.fit(X_train, y_train)
# best_xgb_model = xgb_cv.best_estimator_
# print(f'Best parameters: {xgb_cv.best_params_}')
# print(f'Best score: {xgb_cv.best_score_}')
# y_pred = best_xgb_model.predict(X_test)
# mse = mean_squared_error(y_test, y_pred)
# rmse = np.sqrt(mse)
# print(f'RMSE: {rmse}')
# %%time





forecast_days = 29
last_known_features = X_train.iloc[-1,:]
last_date = new_bitcoin_df['Date'].iloc[-1]
last_date
future_dates = pd.date_range(start=last_date, periods=forecast_days+1, freq='D')
future_dates
forecasted_values = []
for i in range(forecast_days):
  next_prediction = best_xgb_model.predict(last_known_features.values.reshape(1, -1))
  last_known_features = last_known_features.shift(-1)
  last_known_features.iloc[-1] = next_prediction[0]
  forecasted_values.append(next_prediction[0])


forecast_df = pd.DataFrame({'Date': future_dates[1:], 'Forecast Values': forecasted_values})
forecast_df

real_values = bitcoin_df.iloc[:29].sort_values(by='Date')
real_values

plt.plot(forecast_df['Date'], forecast_df['Forecast Values'], label='Forecasted Values')

# Plot DataFrame 2
plt.plot(real_values['Date'], real_values['Open'], label='Actual Values')

# Customize the plot
plt.xlabel('Date')
plt.ylabel('Pric (USD)')
plt.title('XGBoost Model Forecast Values vs. Actual Value Comparison of Bitcoin Prices for Septeber 2024')
plt.legend()

# Rotate x-axis labels
plt.xticks(rotation=45, ha='right')

plt.tight_layout()
plt.show()

'''from sklearn.model_selection import TimeSeriesSplit, GridSearchCV, cross_val_score
from sklearn.metrics import mean_squared_error
tscv = TimeSeriesSplit(n_splits=5)
tscv2 = TimeSeriesSplit(n_splits=5)
xgb_model = XGBRegressor()
param_grid = {
    'n_estimators': [50, 75, 100, 125],
    'learning_rate': [0.01, 0.1, 0.2, 0.3],
    'max_depth': [3, 4, 5, 6],
    'subsample': [0.8, 0.9, 1.0],
    'colsample_bytree': [0.8, 0.9, 1.0],
}
scoring = ['neg_mean_squared_error', ]
xgb_cv = GridSearchCV(xgb_model, param_grid, cv=tscv, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)
nested_scores = cross_val_score(xgb_cv, X_train, y_train, cv=tscv2, scoring='neg_mean_squared_error')
print(f'Nested scores: {nested_scores}')

xgb_cv.fit(X_train, y_train)
best_xgb_model = xgb_cv.best_estimator_
print(f'Best parameters: {xgb_cv.best_params_}')
print(f'Best score: {xgb_cv.best_score_}')
y_pred = best_xgb_model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
print(f'RMSE: {rmse}')'''

from sklearn.metrics import mean_absolute_error, mean_squared_error

# Calculate RMSE
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
print(f'RMSE: {rmse}')

# Calculate MAE
mae = mean_absolute_error(y_test, y_pred)
print(f'MAE: {mae}')

# Calculate MAPE
def mape(y_true, y_pred):
  return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

mape_score = mape(y_test, y_pred)
print(f'MAPE: {mape_score}')